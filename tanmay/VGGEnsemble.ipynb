{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "# !pip install keras_vggface\n",
    "# !pip install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 07:29:55.266034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using VGGFace compatible with TensorFlow2.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from random import choice, sample\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "from tf2_keras_vggface.utils import preprocess_input\n",
    "from tf2_keras_vggface.vggface import VGGFace\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BASE_MODEL = 'vgg16'\n",
    "INPUT_SHAPE = (224, 224,)\n",
    "IGNORE_BOTTOM_NLAYERS_TUNE = -2\n",
    "IGNORE_TOP_NLAYERS_TUNE = 0\n",
    "FINE_TUNE = True\n",
    "\n",
    "# Modify paths as per your method of saving them\n",
    "BASE_PATH = \"/root/KinshipRecognition\"\n",
    "TRAIN_FILE_PATH = f\"{BASE_PATH}/data/aug_train_ds.csv\"\n",
    "TRAIN_FOLDERS_PATH = f\"{BASE_PATH}/data/train/train-faces/\"\n",
    "\n",
    "# Output file\n",
    "MODEL_NAME = f\"ensemble_vggface_{BASE_MODEL}_finetune2_dense32-128-32_drop05\"\n",
    "\n",
    "# All images belonging to families F09** will be used to create the validation set while training the model\n",
    "# For final submission, you can add these to the training data as well\n",
    "# val_families_list = [\"F06\"]\n",
    "val_families_list = [\"F02\",\"F04\",\"F06\",\"F08\", \"F09\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(family_name):\n",
    "\n",
    "    val_families = family_name\n",
    "\n",
    "    all_images = glob(TRAIN_FOLDERS_PATH + \"*/*/*.jpg\")\n",
    "    train_images = [x for x in all_images if val_families not in x]\n",
    "    val_images = [x for x in all_images if val_families in x]\n",
    "\n",
    "    train_person_to_images_map = defaultdict(list)\n",
    "\n",
    "    ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
    "\n",
    "    for x in train_images:\n",
    "        train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "    val_person_to_images_map = defaultdict(list)\n",
    "\n",
    "    for x in val_images:\n",
    "        val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "    relationships = pd.read_csv(TRAIN_FILE_PATH)\n",
    "    relationships = list(zip(relationships.p1.values, relationships.p2.values, relationships.relationship.values))\n",
    "    relationships = [(x[0],x[1],x[2]) for x in relationships if x[0][:10] in ppl and x[1][:10] in ppl]    \n",
    "\n",
    "    train = [x for x in relationships if val_families not in x[0]]\n",
    "    val = [x for x in relationships if val_families in x[0]]\n",
    "    return train, val, train_person_to_images_map, val_person_to_images_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path, input_shape):\n",
    "    img = cv2.imread(path, -1)\n",
    "    img = cv2.resize(img, input_shape)\n",
    "    img = cv2.normalize(img,  np.zeros(img.shape[:2]), 0, 255, cv2.NORM_MINMAX)\n",
    "    return np.array(img).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(list_tuples, person_to_images_map, input_shape, batch_size=16, normalization='base'):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size)\n",
    "        \n",
    "        # All the samples are taken from train_ds.csv, labels are in the labels column\n",
    "        labels = []\n",
    "        for tup in batch_tuples:\n",
    "            labels.append(tup[2])\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Original images preprocessed\n",
    "        X1 = [x[0] for x in batch_tuples]\n",
    "        X1 = np.array([read_img(TRAIN_FOLDERS_PATH + x, input_shape) for x in X1])\n",
    "        \n",
    "        X2 = [x[1] for x in batch_tuples]\n",
    "        X2 = np.array([read_img(TRAIN_FOLDERS_PATH + x, input_shape) for x in X2])\n",
    "        \n",
    "        # Mirrored images\n",
    "        X1_mirror = np.asarray([cv2.flip(x, 1) for x in X1])\n",
    "        X2_mirror = np.asarray([cv2.flip(x, 1) for x in X2])\n",
    "        X1 = np.r_[X1, X1_mirror]\n",
    "        X2 = np.r_[X2, X2_mirror]\n",
    "        \n",
    "        yield [X1, X2], np.r_[labels, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(model_name, fine_tune=True):\n",
    "    input_1 = Input(shape=INPUT_SHAPE + (3,))\n",
    "    input_2 = Input(shape=INPUT_SHAPE + (3,))\n",
    "\n",
    "    backbone = VGGFace(model=model_name, include_top=False)\n",
    "    for x in backbone.layers:\n",
    "        x.trainable = False\n",
    "\n",
    "    if fine_tune:\n",
    "        for x in backbone.layers[:IGNORE_BOTTOM_NLAYERS_TUNE]:\n",
    "            x.trainable = False\n",
    "        if IGNORE_TOP_NLAYERS_TUNE == 0:\n",
    "            for x in backbone.layers[IGNORE_BOTTOM_NLAYERS_TUNE:]:\n",
    "                x.trainable = True\n",
    "        else:\n",
    "            for x in backbone.layers[IGNORE_BOTTOM_NLAYERS_TUNE:-IGNORE_TOP_NLAYERS_TUNE]:\n",
    "                x.trainable = True\n",
    "\n",
    "    for x in backbone.layers:\n",
    "        print(x.name, x.trainable)\n",
    "\n",
    "    x1 = backbone(input_1)\n",
    "    x2 = backbone(input_2)\n",
    "\n",
    "    x1 = GlobalAvgPool2D()(x1)\n",
    "    x2 = GlobalAvgPool2D()(x2)\n",
    "\n",
    "    x1 = LayerNormalization(axis=-1, epsilon=0.001, center=False, scale=False)(x1)\n",
    "    x2 = LayerNormalization(axis=-1, epsilon=0.001, center=False, scale=False)(x2)\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    x5 = Multiply()([x1, x2])\n",
    "    x = Concatenate(axis=-1)([x3, x4, x5])\n",
    "        \n",
    "#     x = LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True)(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(0.05)(x)    \n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.05)(x)    \n",
    "    x = Dense(32, activation=\"tanh\")(x)\n",
    "#     x = LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=False)(x)\n",
    "    x = Dropout(0.05)(x)    \n",
    "    out = Dense(1, kernel_regularizer=L2(.01), activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00002))\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Iteration 0: Validation on F02\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 07:30:17.842260: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-11 07:30:17.843345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-11 07:30:17.950674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-08-11 07:30:17.950708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-11 07:30:17.952214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-11 07:30:17.952272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-08-11 07:30:17.953686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-11 07:30:17.953922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-11 07:30:17.955219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-11 07:30:17.955823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-08-11 07:30:17.959102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-11 07:30:17.963226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-11 07:30:17.963990: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-11 07:30:17.975325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-08-11 07:30:17.975392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-11 07:30:17.975431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-11 07:30:17.975459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-08-11 07:30:17.975486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-11 07:30:17.975512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-11 07:30:17.975539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-11 07:30:17.975565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-08-11 07:30:17.975592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-11 07:30:17.986410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-11 07:30:17.986535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-11 07:30:18.540188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-11 07:30:18.540216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-08-11 07:30:18.540221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-08-11 07:30:18.544139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30130 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n",
      "2021-08-11 07:30:18.544579: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_3 False\n",
      "conv1_1 False\n",
      "conv1_2 False\n",
      "pool1 False\n",
      "conv2_1 False\n",
      "conv2_2 False\n",
      "pool2 False\n",
      "conv3_1 False\n",
      "conv3_2 False\n",
      "conv3_3 False\n",
      "pool3 False\n",
      "conv4_1 False\n",
      "conv4_2 False\n",
      "conv4_3 False\n",
      "pool4 False\n",
      "conv5_1 False\n",
      "conv5_2 False\n",
      "conv5_3 True\n",
      "pool5 True\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_vgg16 (Functional)      (None, None, None, 5 14714688    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           vggface_vgg16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           vggface_vgg16[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 512)          0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 512)          0           layer_normalization[0][0]        \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 512)          0           layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 512)          0           layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 512)          0           subtract[0][0]                   \n",
      "                                                                 subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 512)          0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 512)          0           layer_normalization[0][0]        \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1536)         0           multiply[0][0]                   \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           49184       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          4224        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            33          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,772,257\n",
      "Trainable params: 2,417,377\n",
      "Non-trainable params: 12,354,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 07:30:19.435236: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-11 07:30:19.454995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 07:30:20.320433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-11 07:30:20.511741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 54s 171ms/step - loss: 0.6835 - acc: 0.6235 - val_loss: 0.6388 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65250, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.5670 - acc: 0.7237 - val_loss: 0.6110 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.65250 to 0.67078, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.4995 - acc: 0.7716 - val_loss: 0.6193 - val_acc: 0.6692\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.67078\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.4572 - acc: 0.7991 - val_loss: 0.6121 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.67078 to 0.68703, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.4128 - acc: 0.8261 - val_loss: 0.5679 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.68703 to 0.71188, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.3882 - acc: 0.8371 - val_loss: 0.5659 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.71188 to 0.72344, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.3714 - acc: 0.8461 - val_loss: 0.5829 - val_acc: 0.7153\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72344\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 48s 160ms/step - loss: 0.3479 - acc: 0.8631 - val_loss: 0.5849 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.72344 to 0.72625, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 46s 154ms/step - loss: 0.3288 - acc: 0.8642 - val_loss: 0.5708 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.72625 to 0.73797, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 46s 155ms/step - loss: 0.2990 - acc: 0.8837 - val_loss: 0.5831 - val_acc: 0.7242\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.73797\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 48s 159ms/step - loss: 0.2906 - acc: 0.8896 - val_loss: 0.6117 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.73797\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 48s 162ms/step - loss: 0.2819 - acc: 0.8965 - val_loss: 0.5682 - val_acc: 0.7384\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.73797 to 0.73844, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 49s 165ms/step - loss: 0.2539 - acc: 0.9092 - val_loss: 0.6165 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.73844\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 48s 161ms/step - loss: 0.2669 - acc: 0.8979 - val_loss: 0.6137 - val_acc: 0.7295\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.73844\n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 48s 162ms/step - loss: 0.2541 - acc: 0.9053 - val_loss: 0.5820 - val_acc: 0.7406\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.73844 to 0.74063, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 48s 162ms/step - loss: 0.2334 - acc: 0.9138 - val_loss: 0.6332 - val_acc: 0.7352\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.74063\n",
      "Epoch 17/25\n",
      "300/300 [==============================] - 48s 161ms/step - loss: 0.2344 - acc: 0.9182 - val_loss: 0.6413 - val_acc: 0.7195\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.74063\n",
      "Epoch 18/25\n",
      "300/300 [==============================] - 49s 162ms/step - loss: 0.2443 - acc: 0.9076 - val_loss: 0.6265 - val_acc: 0.7355\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.74063\n",
      "Epoch 19/25\n",
      "300/300 [==============================] - 49s 162ms/step - loss: 0.2436 - acc: 0.9116 - val_loss: 0.6817 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.74063\n",
      "Epoch 20/25\n",
      "300/300 [==============================] - 48s 160ms/step - loss: 0.2394 - acc: 0.9127 - val_loss: 0.6473 - val_acc: 0.7344\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.74063\n",
      "Epoch 21/25\n",
      "300/300 [==============================] - 47s 157ms/step - loss: 0.2200 - acc: 0.9175 - val_loss: 0.6419 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.74063\n",
      "Epoch 22/25\n",
      "300/300 [==============================] - 47s 158ms/step - loss: 0.2091 - acc: 0.9256 - val_loss: 0.6534 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.74063\n",
      "Epoch 23/25\n",
      "300/300 [==============================] - 48s 160ms/step - loss: 0.2218 - acc: 0.9184 - val_loss: 0.6061 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.74063 to 0.74125, saving model to /root/KinshipRecognition/log/model/ensemble_vggface_vgg16_finetune1_dense32-128-32_drop05_0.h5\n",
      "Epoch 24/25\n",
      "300/300 [==============================] - 47s 156ms/step - loss: 0.1907 - acc: 0.9331 - val_loss: 0.6839 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.74125\n",
      "Epoch 25/25\n",
      "300/300 [==============================] - 47s 155ms/step - loss: 0.1846 - acc: 0.9360 - val_loss: 0.6953 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.74125\n",
      "##############################\n",
      "Iteration 1: Validation on F04\n",
      "##############################\n",
      "input_6 False\n",
      "conv1_1 False\n",
      "conv1_2 False\n",
      "pool1 False\n",
      "conv2_1 False\n",
      "conv2_2 False\n",
      "pool2 False\n",
      "conv3_1 False\n",
      "conv3_2 False\n",
      "conv3_3 False\n",
      "pool3 False\n",
      "conv4_1 False\n",
      "conv4_2 False\n",
      "conv4_3 False\n",
      "pool4 False\n",
      "conv5_1 False\n",
      "conv5_2 False\n",
      "conv5_3 True\n",
      "pool5 True\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_vgg16 (Functional)      (None, None, None, 5 14714688    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           vggface_vgg16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 512)          0           vggface_vgg16[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 512)          0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 512)          0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 512)          0           layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 512)          0           layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 512)          0           layer_normalization_3[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 512)          0           subtract_2[0][0]                 \n",
      "                                                                 subtract_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 512)          0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 512)          0           layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1536)         0           multiply_4[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           49184       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          4224        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           4128        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            33          dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,772,257\n",
      "Trainable params: 2,417,377\n",
      "Non-trainable params: 12,354,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "133/300 [============>.................] - ETA: 17s - loss: 0.7816 - acc: 0.5518"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_families_list)):\n",
    "\n",
    "    print('##############################')\n",
    "    print(f'Iteration {i}: Validation on {val_families_list[i]}')\n",
    "    print('##############################')\n",
    "\n",
    "    train, val, train_person_to_images_map, val_person_to_images_map = get_train_val(val_families_list[i])\n",
    "    file_path = f\"{BASE_PATH}/log/model/{MODEL_NAME}_{i}.h5\"\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.3, patience=30, verbose=1)\n",
    "    callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "    \n",
    "    model = baseline_model(BASE_MODEL, fine_tune=FINE_TUNE)\n",
    "    \n",
    "    history = model.fit(gen(train, train_person_to_images_map, INPUT_SHAPE, batch_size=16), \n",
    "                        validation_data=gen(val, val_person_to_images_map, INPUT_SHAPE, batch_size=16), \n",
    "                        epochs=25, steps_per_epoch=300, validation_steps=200,\n",
    "                        verbose=1, callbacks=callbacks_list, \n",
    "                        use_multiprocessing=False, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f\"{BASE_PATH}/data/test/\"\n",
    "submission = pd.read_csv(f'{BASE_PATH}/data/test_ds.csv')\n",
    "preds_for_sub = np.zeros(submission.shape[0])\n",
    "all_preds = list()\n",
    "for i in range(len(val_families_list)):\n",
    "\n",
    "    print('##############################')\n",
    "    print(f'Iteration {i}: Validation on {val_families_list[i]}')\n",
    "    print('##############################')\n",
    "    \n",
    "    model = baseline_model(BASE_MODEL, fine_tune=FINE_TUNE)\n",
    "    file_path = f\"{BASE_PATH}/log/model/{MODEL_NAME}_{i}.h5\"\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = []\n",
    "    for j in range(0, len(submission.p1.values), 32):\n",
    "        X1 = submission.p1.values[j:j+32]\n",
    "        X1 = np.array([read_img(test_path + x, INPUT_SHAPE) for x in X1])\n",
    "\n",
    "        X2 = submission.p2.values[j:j+32]\n",
    "        X2 = np.array([read_img(test_path + x, INPUT_SHAPE) for x in X2])\n",
    "\n",
    "        pred = model.predict([X1, X2]).ravel().tolist()\n",
    "        predictions += pred    \n",
    "    \n",
    "    all_preds.append(np.array(predictions))\n",
    "    preds_for_sub += np.array(predictions) / len(val_families_list)\n",
    "\n",
    "    \n",
    "all_preds = np.asarray(all_preds)\n",
    "submission['score'] = preds_for_sub\n",
    "pd.DataFrame(all_preds).to_csv(f\"{BASE_PATH}/log/results/{MODEL_NAME}_allpreds.csv\", index=False)\n",
    "submission.to_csv(f\"{BASE_PATH}/log/results/{MODEL_NAME}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(preds_for_sub <= 0.5))\n",
    "print(len(preds_for_sub), '\\n')\n",
    "for line in preds_for_sub:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

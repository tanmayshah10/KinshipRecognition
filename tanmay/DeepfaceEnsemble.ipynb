{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_vggface\n",
    "# !pip install keras_applications\n",
    "# !pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 20:00:04.966940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from random import choice, sample\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "from deepface.commons.functions import find_input_shape, normalize_input\n",
    "from deepface.DeepFace import build_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 20:00:06.408146: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-10 20:00:06.409962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-10 20:00:06.449310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-08-10 20:00:06.449354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-10 20:00:06.451895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-10 20:00:06.451958: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-08-10 20:00:06.453646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-10 20:00:06.453947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-10 20:00:06.455928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-10 20:00:06.457064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-08-10 20:00:06.461433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-10 20:00:06.464551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-10 20:00:06.464916: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-10 20:00:06.471488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-08-10 20:00:06.471516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-10 20:00:06.471534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-10 20:00:06.471542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-08-10 20:00:06.471550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-10 20:00:06.471558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-10 20:00:06.471566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-10 20:00:06.471574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-08-10 20:00:06.471582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-10 20:00:06.474083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-10 20:00:06.474113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-10 20:00:06.989921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-10 20:00:06.989951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-08-10 20:00:06.989982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-08-10 20:00:06.993801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29704 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n",
      "2021-08-10 20:00:06.994205: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "BASE_MODEL = 'DeepFace'\n",
    "IGNORE_TOP_NLAYERS_ARCH = 2 \n",
    "IGNORE_BOTTOM_NLAYERS_TUNE = 1\n",
    "IGNORE_TOP_NLAYERS_TUNE = 1\n",
    "NORMALIZATION = 'base'\n",
    "FINE_TUNE = False\n",
    "\n",
    "# Modify paths as per your method of saving them\n",
    "BASE_PATH = \"/root/KinshipRecognition\"\n",
    "TRAIN_FILE_PATH = f\"{BASE_PATH}/data/aug_train_ds.csv\"\n",
    "TRAIN_FOLDERS_PATH = f\"{BASE_PATH}/data/train/train-faces/\"\n",
    "\n",
    "# All images belonging to families F09** will be used to create the validation set while training the model\n",
    "# For final submission, you can add these to the training data as well\n",
    "val_families_list = [\"F06\"]\n",
    "# val_families_list = [\"F09\",\"F04\",\"F08\",\"F06\", \"F02\"]\n",
    "\n",
    "# Output file\n",
    "MODEL_NAME = f\"jd_ensemble_deepface_{BASE_MODEL}_notune_dense32-128-32_drop05\"\n",
    "\n",
    "# Get input shape and normalization method.\n",
    "INPUT_SHAPE = find_input_shape(build_model(BASE_MODEL))\n",
    "NORMALIZATION = 'base' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(family_name):\n",
    "\n",
    "    val_families = family_name\n",
    "\n",
    "    all_images = glob(TRAIN_FOLDERS_PATH + \"*/*/*.jpg\")\n",
    "    train_images = [x for x in all_images if val_families not in x]\n",
    "    val_images = [x for x in all_images if val_families in x]\n",
    "\n",
    "    train_person_to_images_map = defaultdict(list)\n",
    "\n",
    "    ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
    "\n",
    "    for x in train_images:\n",
    "        train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "    val_person_to_images_map = defaultdict(list)\n",
    "\n",
    "    for x in val_images:\n",
    "        val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "    relationships = pd.read_csv(TRAIN_FILE_PATH)\n",
    "    relationships = list(zip(relationships.p1.values, relationships.p2.values, relationships.relationship.values))\n",
    "    relationships = [(x[0],x[1],x[2]) for x in relationships if x[0][:10] in ppl and x[1][:10] in ppl]    \n",
    "\n",
    "    train = [x for x in relationships if val_families not in x[0]]\n",
    "    val = [x for x in relationships if val_families in x[0]]\n",
    "    return train, val, train_person_to_images_map, val_person_to_images_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path, input_shape, normalization='base'):\n",
    "    img = cv2.imread(path, -1)\n",
    "    img = cv2.resize(img, input_shape)\n",
    "    img = cv2.normalize(img,  np.zeros(img.shape[:2]), 0, 255, cv2.NORM_MINMAX)\n",
    "    img = normalize_input(img, normalization=NORMALIZATION)\n",
    "    return np.array(img).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(list_tuples, person_to_images_map, input_shape, batch_size=16, normalization='base'):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size)\n",
    "        \n",
    "        # All the samples are taken from train_ds.csv, labels are in the labels column\n",
    "        labels = []\n",
    "        for tup in batch_tuples:\n",
    "            labels.append(tup[2])\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Original images preprocessed\n",
    "        X1 = [x[0] for x in batch_tuples]\n",
    "        X1 = np.array([read_img(TRAIN_FOLDERS_PATH + x, input_shape) for x in X1])\n",
    "        \n",
    "        X2 = [x[1] for x in batch_tuples]\n",
    "        X2 = np.array([read_img(TRAIN_FOLDERS_PATH + x, input_shape) for x in X2])\n",
    "        \n",
    "        # Mirrored images\n",
    "        X1_mirror = np.asarray([cv2.flip(x, 1) for x in X1])\n",
    "        X2_mirror = np.asarray([cv2.flip(x, 1) for x in X2])\n",
    "        X1 = np.r_[X1, X1_mirror]\n",
    "        X2 = np.r_[X2, X2_mirror]\n",
    "        \n",
    "        yield [X1, X2], np.r_[labels, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(model_name, fine_tune=True):\n",
    "    input_shape=(224,224)\n",
    "    input_1 = Input(shape=input_shape + (3,))\n",
    "    input_2 = Input(shape=input_shape + (3,))\n",
    "\n",
    "    backbone = Sequential()\n",
    "    for layer in build_model(model_name).layers[:-IGNORE_TOP_NLAYERS_ARCH]:\n",
    "        backbone.add(layer)\n",
    "    for x in backbone.layers:\n",
    "        x.trainable = False\n",
    "\n",
    "    if fine_tune:\n",
    "        for x in backbone.layers[:IGNORE_BOTTOM_NLAYERS_TUNE]:\n",
    "            x.trainable = False\n",
    "        if IGNORE_TOP_NLAYERS_TUNE == 0:\n",
    "            for x in backbone.layers[IGNORE_BOTTOM_NLAYERS_TUNE:]:\n",
    "                x.trainable = True\n",
    "        else:\n",
    "            for x in backbone.layers[IGNORE_BOTTOM_NLAYERS_TUNE:-IGNORE_TOP_NLAYERS_TUNE]:\n",
    "                x.trainable = True\n",
    "\n",
    "    x1 = backbone(input_1)\n",
    "    x2 = backbone(input_2)\n",
    "\n",
    "    x1 = GlobalAvgPool2D()(x1)\n",
    "    x2 = GlobalAvgPool2D()(x2)\n",
    "\n",
    "    x1 = LayerNormalization(axis=-1, epsilon=0.001, center=False, scale=False)(x1)\n",
    "    x2 = LayerNormalization(axis=-1, epsilon=0.001, center=False, scale=False)(x2)\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    x5 = Multiply()([x1, x2])\n",
    "    x = Concatenate(axis=-1)([x3, x4, x5])\n",
    "        \n",
    "#     x = LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True)(x)\n",
    "    \n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(0.05)(x)    \n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.05)(x)    \n",
    "    x = Dense(32, activation=\"relu\", kernel_regularizer=L2(.0001))(x)\n",
    "    x = Dropout(0.05)(x) \n",
    "    x = Dense(32, activation=\"tanh\")(x)\n",
    "    #   x = LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=False)(x)\n",
    "    x = Dropout(0.05)(x)    \n",
    "    out = Dense(1, kernel_regularizer=L2(.01), activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.0001)) #LR changed\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Iteration 0: Validation on F06\n",
      "##############################\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 21, 21, 16)   73507392    input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 16)           0           sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 16)           0           sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 16)           0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 16)           0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 16)           0           layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 16)           0           layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 16)           0           layer_normalization_3[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 16)           0           subtract_2[0][0]                 \n",
      "                                                                 subtract_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 16)           0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 16)           0           layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48)           0           multiply_4[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           1568        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          4224        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           4128        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           1056        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            33          dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 73,518,401\n",
      "Trainable params: 11,009\n",
      "Non-trainable params: 73,507,392\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/25\n",
      "300/300 [==============================] - 266s 424ms/step - loss: 0.7166 - acc: 0.5672 - val_loss: 0.6344 - val_acc: 0.7105\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71047, saving model to /root/KinshipRecognition/log/model/jd_ensemble_deepface_DeepFace_notune_dense32-128-32_drop05_0.h5\n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 62s 207ms/step - loss: 0.6623 - acc: 0.6565 - val_loss: 0.6245 - val_acc: 0.7203\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71047 to 0.72031, saving model to /root/KinshipRecognition/log/model/jd_ensemble_deepface_DeepFace_notune_dense32-128-32_drop05_0.h5\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 62s 205ms/step - loss: 0.6499 - acc: 0.6704 - val_loss: 0.6319 - val_acc: 0.7161\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.72031\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.6601 - acc: 0.6552 - val_loss: 0.6295 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72031\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 61s 205ms/step - loss: 0.6669 - acc: 0.6466 - val_loss: 0.6159 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72031 to 0.72531, saving model to /root/KinshipRecognition/log/model/jd_ensemble_deepface_DeepFace_notune_dense32-128-32_drop05_0.h5\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.6577 - acc: 0.6558 - val_loss: 0.6186 - val_acc: 0.7128\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72531\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 63s 210ms/step - loss: 0.6492 - acc: 0.6706 - val_loss: 0.6157 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72531\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.6499 - acc: 0.6656 - val_loss: 0.6250 - val_acc: 0.7106\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.72531\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 62s 205ms/step - loss: 0.6525 - acc: 0.6568 - val_loss: 0.6183 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.72531\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 61s 205ms/step - loss: 0.6474 - acc: 0.6642 - val_loss: 0.6086 - val_acc: 0.7322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_acc improved from 0.72531 to 0.73219, saving model to /root/KinshipRecognition/log/model/jd_ensemble_deepface_DeepFace_notune_dense32-128-32_drop05_0.h5\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.6449 - acc: 0.6691 - val_loss: 0.6139 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.73219\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 62s 205ms/step - loss: 0.6541 - acc: 0.6567 - val_loss: 0.6295 - val_acc: 0.7016\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.73219\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.6550 - acc: 0.6485 - val_loss: 0.6160 - val_acc: 0.7161\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.73219\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.6467 - acc: 0.6614 - val_loss: 0.6220 - val_acc: 0.7084\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.73219\n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.6520 - acc: 0.6526 - val_loss: 0.6239 - val_acc: 0.7044\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.73219\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 61s 205ms/step - loss: 0.6431 - acc: 0.6605 - val_loss: 0.6174 - val_acc: 0.7145\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.73219\n",
      "Epoch 17/25\n",
      "300/300 [==============================] - 62s 207ms/step - loss: 0.6481 - acc: 0.6604 - val_loss: 0.6196 - val_acc: 0.7073\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.73219\n",
      "Epoch 18/25\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.6366 - acc: 0.6744 - val_loss: 0.6142 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.73219\n",
      "Epoch 19/25\n",
      "300/300 [==============================] - 59s 198ms/step - loss: 0.6410 - acc: 0.6649 - val_loss: 0.6085 - val_acc: 0.7214\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.73219\n",
      "Epoch 20/25\n",
      "300/300 [==============================] - 59s 197ms/step - loss: 0.6457 - acc: 0.6534 - val_loss: 0.6163 - val_acc: 0.7117\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.73219\n",
      "Epoch 21/25\n",
      "300/300 [==============================] - 58s 194ms/step - loss: 0.6423 - acc: 0.6550 - val_loss: 0.6157 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.73219\n",
      "Epoch 22/25\n",
      "300/300 [==============================] - 60s 200ms/step - loss: 0.6457 - acc: 0.6558 - val_loss: 0.6180 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.73219\n",
      "Epoch 23/25\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.6288 - acc: 0.6747 - val_loss: 0.6188 - val_acc: 0.7064\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.73219\n",
      "Epoch 24/25\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.6330 - acc: 0.6746 - val_loss: 0.6090 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.73219\n",
      "Epoch 25/25\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.6406 - acc: 0.6633"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_families_list)):\n",
    "\n",
    "    print('##############################')\n",
    "    print(f'Iteration {i}: Validation on {val_families_list[i]}')\n",
    "    print('##############################')\n",
    "\n",
    "    train, val, train_person_to_images_map, val_person_to_images_map = get_train_val(val_families_list[i])\n",
    "    file_path = f\"{BASE_PATH}/log/model/{MODEL_NAME}_{i}.h5\"\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.3, patience=30, verbose=1)\n",
    "    callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "    \n",
    "    model = baseline_model(BASE_MODEL, fine_tune=FINE_TUNE)\n",
    "    \n",
    "    history = model.fit(gen(train, train_person_to_images_map, INPUT_SHAPE, batch_size=16), \n",
    "                        validation_data=gen(val, val_person_to_images_map, INPUT_SHAPE, batch_size=16), \n",
    "                        epochs=25, steps_per_epoch=300, validation_steps=200,\n",
    "                        verbose=1, callbacks=callbacks_list, \n",
    "                        use_multiprocessing=False, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f\"{BASE_PATH}/data/test/\"\n",
    "submission = pd.read_csv(f'{BASE_PATH}/data/test_ds.csv')\n",
    "preds_for_sub = np.zeros(submission.shape[0])\n",
    "all_preds = list()\n",
    "for i in range(len(val_families_list)):\n",
    "\n",
    "    print('##############################')\n",
    "    print(f'Iteration {i}: Validation on {val_families_list[i]}')\n",
    "    print('##############################')\n",
    "    \n",
    "    model = baseline_model(BASE_MODEL, fine_tune=FINE_TUNE)\n",
    "    file_path = f\"{BASE_PATH}/log/model/{MODEL_NAME}_{i}.h5\"\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = []\n",
    "    for j in range(0, len(submission.p1.values), 32):\n",
    "        X1 = submission.p1.values[j:j+32]\n",
    "        X1 = np.array([read_img(test_path + x, INPUT_SHAPE) for x in X1])\n",
    "\n",
    "        X2 = submission.p2.values[j:j+32]\n",
    "        X2 = np.array([read_img(test_path + x, INPUT_SHAPE) for x in X2])\n",
    "\n",
    "        pred = model.predict([X1, X2]).ravel().tolist()\n",
    "        predictions += pred    \n",
    "    \n",
    "    all_preds.append(np.array(predictions))\n",
    "    preds_for_sub += np.array(predictions) / len(val_families_list)\n",
    "\n",
    "    \n",
    "all_preds = np.asarray(all_preds)\n",
    "submission['score'] = preds_for_sub\n",
    "pd.DataFrame(all_preds).to_csv(f\"{BASE_PATH}/log/results/{MODEL_NAME}_allpreds.csv\", index=False)\n",
    "submission.to_csv(f\"{BASE_PATH}/log/results/{MODEL_NAME}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(pred_for_sub <= 0.5))\n",
    "print(len(pred_for_sub) + '\\n')\n",
    "for line in preds_for_sub:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

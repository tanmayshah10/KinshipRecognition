{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c38aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29ea199",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/root/KinshipRecognition\"\n",
    "TRAIN_FILE = f\"{BASE_PATH}/data/train_ds.csv\"\n",
    "TRAIN_FOLDERS = f\"{BASE_PATH}/data/train/train-faces\"\n",
    "MAX_SAMPLES_PER_PAIR = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42aebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data index\n",
    "train_ds = np.asarray(pd.read_csv(TRAIN_FILE))[:, 1:]\n",
    "# Sort by label\n",
    "ds_by_label = dict()\n",
    "for label in np.unique(train_ds[:, -1]):\n",
    "    ds_by_label[label] = train_ds[np.where(train_ds[:, -1] == label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d77c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augments existing kin and non-kin samples\n",
    "def augment_train_ds(ds_by_label, exclude_labels=None):\n",
    "    for label in ds_by_label.keys():\n",
    "        if exclude_labels and label not in exclude_labels:\n",
    "            sample_list = list()\n",
    "            ds_samples = ds_by_label[label]\n",
    "            for tup in ds_samples:\n",
    "                mid_1 = os.listdir(f\"{TRAIN_FOLDERS}/{'/'.join(tup[0].split('/')[:2])}\")\n",
    "                mid_1.remove(tup[0].split('/')[-1])\n",
    "                mid_1 = [f\"{'/'.join(tup[0].split('/')[:2])}/{f}\" for f in mid_1]\n",
    "                mid_2 = os.listdir(f\"{TRAIN_FOLDERS}/{'/'.join(tup[1].split('/')[:2])}\")\n",
    "                mid_2.remove(tup[1].split('/')[-1])\n",
    "                mid_2 = [f\"{'/'.join(tup[1].split('/')[:2])}/{f}\" for f in mid_2]\n",
    "                combos = np.stack(np.meshgrid(mid_1, mid_2), -1).reshape(-1, 2)\n",
    "                combos = np.c_[combos.astype(object), np.ones([len(combos), 1]).astype(int) * label]\n",
    "                if len(combos) > MAX_SAMPLES_PER_PAIR:\n",
    "                    samples = list(combos[np.random.randint(0, len(combos), MAX_SAMPLES_PER_PAIR)])\n",
    "                    [sample_list.append(s) for s in samples]\n",
    "                else:\n",
    "                    samples = list(combos)\n",
    "                    [sample_list.append(s) for s in samples]\n",
    "            aug_ds_samples = np.r_[ds_samples, np.asarray(sample_list)]        \n",
    "            ds_by_label[label] = aug_ds_samples\n",
    "    return ds_by_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88846bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates non-kin samples\n",
    "def expand_train_ds(n_expand_samples, label=0):\n",
    "    families = os.listdir(TRAIN_FOLDERS)\n",
    "    sample_list = list()\n",
    "    while len(sample_list) < n_expand_samples:\n",
    "        fam_1 = np.random.choice(families)\n",
    "        fam_2 = np.random.choice(families)\n",
    "        if fam_1 != fam_2:\n",
    "            fam_1_list = ['/'.join(x.split('/')[-3:]) for x in glob(f\"{TRAIN_FOLDERS}/{fam_1}/*/*\")]\n",
    "            fam_2_list = ['/'.join(x.split('/')[-3:]) for x in glob(f\"{TRAIN_FOLDERS}/{fam_2}/*/*\")]\n",
    "            combos = np.stack(np.meshgrid(fam_1_list, fam_2_list), -1).reshape(-1, 2)\n",
    "            combos = np.c_[combos.astype(object), np.ones([len(combos), 1]).astype(int) * label]\n",
    "            if len(combos) > MAX_SAMPLES_PER_PAIR:\n",
    "                samples = list(combos[np.random.randint(0, len(combos), MAX_SAMPLES_PER_PAIR)])\n",
    "                [sample_list.append(s) for s in samples]\n",
    "            else:\n",
    "                samples = list(combos)\n",
    "                [sample_list.append(s) for s in samples]\n",
    "    return np.asarray(sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed05ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment existing dataset.\n",
    "aug_ds_by_label = augment_train_ds(ds_by_label, exclude_labels=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e310b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of 0-samples to 1-samples\n",
    "ZEROS_RATIO = 1\n",
    "scale = (len(aug_ds_by_label[1]) / len(aug_ds_by_label[0]) * ZEROS_RATIO) - 1\n",
    "if scale >= 1:\n",
    "    # Expand dataset by adding 0-labelled samples\n",
    "    n_expand_samples = int(scale * len(aug_ds_by_label[0]))\n",
    "    ds_zeros = expand_train_ds(n_expand_samples, label=0)\n",
    "    # Append expanded samples to augmented samples\n",
    "    aug_ds_by_label[0] = np.r_[aug_ds_by_label[0], ds_zeros]\n",
    "else:\n",
    "    print(\"Ratio requires truncating the dataset. This function only augments the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb6b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataframe and save to .csv\n",
    "aug_ds = np.r_[aug_ds_by_label[0], aug_ds_by_label[1]]\n",
    "aug_ds = pd.DataFrame(aug_ds)\n",
    "aug_ds.columns = ['p1', 'p2', 'relationship']\n",
    "aug_ds.to_csv(f\"{BASE_PATH}/data/aug_train_ds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59d294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
